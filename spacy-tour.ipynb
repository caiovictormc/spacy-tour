{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = nlp(u'Caio é um rapaz muito bonito e pobre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caio\n",
      "é\n",
      "um\n",
      "rapaz\n",
      "muito\n",
      "bonito\n",
      "e\n",
      "pobre\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caio caio PROPN PROP|M|S|@SUBJ> nsubj Xxxx True False\n",
      "é ser VERB <mv>|V|PR|3S|IND|@FS-STA cop x True True\n",
      "um um DET <arti>|ART|M|S|@>N det xx True True\n",
      "rapaz rapaz NOUN <np-idf>|N|M|S|@<SC ROOT xxxx True False\n",
      "muito muito ADV <quant>|ADV|@>A advmod xxxx True True\n",
      "bonito bonito ADJ <first-cjt>|ADJ|M|S|@N< amod xxxx True False\n",
      "e e CCONJ <co-postnom>|KC|@CO cc x True False\n",
      "pobre pobre ADJ <cjt>|ADJ|M|S|@N< conj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caio 0 4 PER\n",
      "Aeroporto Petronio Portela 53 79 LOC\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Caio é um rapaz muito bonito e pobre que trabalha no Aeroporto Petronio Portela')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quero ir de 0 11 MISC\n",
      "Teresina 12 20 LOC\n",
      "Paris 26 31 LOC\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Quero ir de Teresina para Paris')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.484317\n",
      "0.124764\n",
      "0.484317\n",
      "1.0\n",
      "0.37698\n",
      "0.124764\n",
      "0.37698\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'gato macaco pavão')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Na tentativa de não passar fome, nosso herói tenta insistir continuar brincando com computador.\n",
      "Até um dia a pobreza o cosumirá por completo\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Na tentativa de não passar fome, nosso herói tenta insistir continuar brincando com computador. Até um dia a pobreza o cosumirá por completo')\n",
    "sentences = list(doc.sents)\n",
    "print(len(sentences))\n",
    "print(sentences[0].text)\n",
    "print(sentences[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Teresina', 0, 8, 'LOC')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Teresina é uma cidade muito peba')\n",
    "ents = [(ent.text, ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
    "print(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "# doc_dep  = nlp(u'Isto é uma sentença')\n",
    "# displacy.serve(doc_dep, style='dep', port=8181)\n",
    "\n",
    "doc_ent = nlp(u'Quando comecei a programar não sabia que iria passar fome')\n",
    "displacy.serve(doc_ent, style='ent', port=8181)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lang = 'pt'\n",
    "cls = spacy.util.get_lang_class(lang)   #Language instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Como como SCONJ KS|@SUB advmod Xxxx True False\n",
      "uma umar DET <arti>|ART|F|S|@>N det xxx True True\n",
      "pedra pedrar NOUN <np-idf>|N|F|S|@SUBJ> nsubj xxxx True False\n",
      "pode poder VERB <mv>|V|PR|3S|IND|@FS-STA aux xxxx True True\n",
      "voar voar ADJ ADJ|F|S|@N< ROOT xxxx True False\n",
      "tão tão ADV <dem>|<quant>|ADV|@>A advmod xxx True True\n",
      "alto alto ADJ ADJ|M|S|@N< xcomp xxxx True False\n",
      "? ? PUNCT PU|@PU punct ? False False\n"
     ]
    }
   ],
   "source": [
    "# Rule-based morphology\n",
    "\n",
    "doc = nlp(u'Como uma pedra pode voar tão alto?')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carros nsubj causar VERB [velocidade]\n",
      "em case velocidade NOUN []\n",
      "alta amod velocidade NOUN []\n",
      "velocidade nmod Carros NOUN [em, alta]\n",
      "podem aux causar VERB []\n",
      "causar ROOT causar VERB [Carros, podem, acidentes, .]\n",
      "acidentes obj causar VERB [destruir]\n",
      "e cc destruir VERB []\n",
      "destruir conj acidentes NOUN [e, familias]\n",
      "familias obj destruir VERB [inteiras]\n",
      "inteiras amod familias NOUN []\n",
      ". punct causar VERB []\n",
      "Um nummod dia NOUN []\n",
      "dia obl achar VERB [Um]\n",
      "os det fabricantes SYM []\n",
      "fabricantes nsubj achar VERB [os, carros]\n",
      "de case carros NOUN []\n",
      "carros nmod fabricantes SYM [de]\n",
      "devem aux achar VERB []\n",
      "achar ROOT achar VERB [dia, fabricantes, devem, alternativas, minimizar]\n",
      "alternativas obj achar VERB []\n",
      "para mark minimizar VERB []\n",
      "minimizar advcl achar VERB [para, tipo]\n",
      "esse det tipo NOUN []\n",
      "tipo obj minimizar VERB [esse, caso]\n",
      "de case caso NOUN []\n",
      "caso nmod tipo NOUN [de]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Carros em alta velocidade podem causar acidentes e destruir familias inteiras. Um dia os fabricantes de carros devem achar alternativas para minimizar esse tipo de caso')\n",
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "          [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('São Paulo', 0, 9, 'LOC')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u'São Paulo é considerado um estado desenvolvido')\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt')\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "terminology_list = ['Lula', 'Bolsonaro']\n",
    "patterns = [nlp(text) for text in terminology_list]\n",
    "matcher.add('TerminologyList', None, *patterns)\n",
    "\n",
    "doc = nlp(u\"Lula é o candidato do PT.\"\n",
    "          u\"Bolsonaro é o candidato do PP.\")\n",
    "matches = matcher(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775812107132\n",
      "0.550468104595\n",
      "0.48554967355\n",
      "0.934221638748\n"
     ]
    }
   ],
   "source": [
    "# Similarity\n",
    "\n",
    "nlp = spacy.load('pt')\n",
    "\n",
    "doc1 = nlp(u'Quero fazer um pedido')\n",
    "doc2 = nlp(u'Quero um sanduiche')\n",
    "doc3 = nlp(u'Quero o cardapio')\n",
    "doc4 = nlp(u'Gostaria de pedir um carro')\n",
    "# doc4 = nlp(u'Gostaria de pedir o cardapio')\n",
    "\n",
    "exp = nlp(u'Gostaria de fazer um pedido')\n",
    "\n",
    "for i in [doc1, doc2, doc3, doc4]:\n",
    "    print(exp.similarity(i))\n",
    "\n",
    "# for doc in [doc1, doc2, doc3]:\n",
    "#     for other_doc in [doc1, doc2, doc3]:\n",
    "#         print(doc.similarity(other_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
